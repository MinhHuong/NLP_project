{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model and Issuing predictions (main script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries takes 0.0160 s\n"
     ]
    }
   ],
   "source": [
    "# import time to find consuming steps\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# utility libraries\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import csv\n",
    "from sklearn import preprocessing as pre\n",
    "import re\n",
    "\n",
    "# working with text\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# classifier for classification\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# plotting stuffs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "end = time.time()\n",
    "print('Loading libraries takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset (training, testing, node information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/' # path to the data\n",
    "path_submission = '../submission/' # path to submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading node information takes 0.2810 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read in node informations ====== #\n",
    "with open(path_data + 'node_information.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info = list(reader)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print('Reading node information takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set takes 3.1360 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training data as str ====== #\n",
    "training = np.genfromtxt(path_data + 'training_set.txt', dtype=str)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training set takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing set takes 0.1700 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read testing data as str ====== #\n",
    "testing = np.genfromtxt(path_data + 'testing_set.txt', dtype=str)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading testing set takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(nodes, edges):\n",
    "    '''\n",
    "    Build a graph using igraph library\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nodes: a list of nodes\n",
    "    edges: a list of tuples (source, target)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a graph g\n",
    "    '''\n",
    "    g = ig.Graph(directed=False) # create an undirected graph\n",
    "    g.add_vertices(nodes) # add nodes\n",
    "    g.add_edges(edges) # add edges\n",
    "    \n",
    "    #betweenness = [(v['name'], g.betweenness(v, directed=False, cutoff=3)) for v in g.vs]\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Graph.summary of <igraph.Graph object at 0x00000000174A25E8>>\n"
     ]
    }
   ],
   "source": [
    "# a function used to build small graph for test purpose\n",
    "def test_graph():\n",
    "    nodes = ['hello','this','is','my','test']\n",
    "    edges = [(0,1), (0,3), (1,4), (3,2), (4,3)]\n",
    "    gr = build_graph(nodes, edges)\n",
    "    print(gr.summary)\n",
    "    \n",
    "gr = test_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to preprocess text\n",
    "def preprocess(text, dg_removal=True, sw_removal=True, stemming=True):\n",
    "    '''\n",
    "    Preprocess text: stopword removal, stemming, digit removal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: text on which preprocessing is applied\n",
    "    dg_removal: whether to apply digit removal or not\n",
    "    sw_removal: whether to apply stopword removal or not\n",
    "    stemming: whether to apply stemming or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the text after preprocessing\n",
    "    '''\n",
    "    result = text\n",
    "    \n",
    "    sw = set(nltk.corpus.stopwords.words('english')) # set of stopwords\n",
    "    stemmer = nltk.stem.PorterStemmer() # stemmer\n",
    "    \n",
    "    if dg_removal:\n",
    "        result = re.sub('[0-9]', '', result)\n",
    "    \n",
    "    if sw_removal:\n",
    "        result = ' '.join([token for token in result.split() if token not in sw])\n",
    "        \n",
    "    if stemming:\n",
    "        result = ' '.join([stemmer.stem(token) for token in result.split()])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(ds, g, scale=False):\n",
    "    '''\n",
    "    Compute the set of predefined features from the given dataset (training/testing)\n",
    "    - cosine similarity between abstracts (texts already preprocessed)\n",
    "    - temporal difference in term of publication year\n",
    "    - number of common authors\n",
    "    - whether two articles were published in the same journal\n",
    "    - number of overlapped words in preprocessed title\n",
    "    - average degree of both nodes (because orientation is not taken into account)\n",
    "    - number of common neighbors in the graph\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: dataset to compute features from\n",
    "    g: citation graph\n",
    "    betweenness: betweenness centrality of every node (already computed when building graph)\n",
    "    scale: whether to scale the features or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An array of computed features\n",
    "    '''\n",
    "    size = len(ds)\n",
    "    \n",
    "    cosines = np.zeros(size) # feature \"Cosine similarities\", between each abstract (already preprocessed)\n",
    "    temp_diff = [] # feature \"Temporal distance\" i.e. integer values --> numerical feature\n",
    "    common_auth = [] # feature \"Number of common authors\" i.e. integer values --> numerical feature\n",
    "    same_journal = [] # feature \"Same journal\" i.e. binary label 0/1 --> categorical feature\n",
    "    overlap_title = [] # feature \"Overlapping title\" i.e. number of common words in title\n",
    "    avg_degrees = [] # feature \"Average degree\" i.e. the average degree of two nodes participating in the edge\n",
    "    common_neigh = [] # feature \"Common neighbors\" i.e. the citations cited in common between two nodes\n",
    "    jaccard_coeff = [] # feature \"Jaccard coefficient\" i.e. the relative number of common neighbors\n",
    "    \n",
    "    #betw_centrality = [] # feature \"Betweenness centrality\" i.e. the difference of betweenness of two connected nodes\n",
    "    \n",
    "    for i in range(size):\n",
    "        src, dest = ds[i][0], ds[i][1] # get the source and dest ID\n",
    "        src_info, dest_info = node_info[ID.index(src)], node_info[ID.index(dest)] # get the associated node information\n",
    "    \n",
    "        # collect the cosine similarity\n",
    "        src_vect, dest_vect = tfidf[ID.index(src)], tfidf[ID.index(dest)] # get the corresponding vector in TD-IDF matrix\n",
    "        cos = cosine_similarity(src_vect, dest_vect) # compute cosine similarity\n",
    "        cosines[i] = cos\n",
    "        \n",
    "        # collect the temporal difference (in absolute value)\n",
    "        temp_diff.append(\n",
    "            abs(int(src_info[1]) - int(dest_info[1]))\n",
    "        )\n",
    "    \n",
    "        # collect the number of common authors\n",
    "        common_auth.append(len(\n",
    "            set(src_info[3].split(',')).intersection(set(dest_info[3].split(',')))\n",
    "        ))\n",
    "    \n",
    "        # collect the information whether the two 2 articles were published in the same journal\n",
    "        same_journal.append(int(\n",
    "            len(src_info[4])>0 and  # journal info of source not null\n",
    "            len(dest_info[4])>0 and # journal info of dest not null\n",
    "            src_info[4] == dest_info[4] # the same journal title\n",
    "        ))\n",
    "        \n",
    "        # collect the number of overlapping words in title\n",
    "        src_title, dest_title = preprocess(src_info[2]).split(), preprocess(dest_info[2]).split()\n",
    "        overlap_title.append(len(\n",
    "            set(src_title).intersection(set(dest_title))\n",
    "        ))\n",
    "        \n",
    "        # collect the average degree\n",
    "        src_deg, dest_deg = g.degree(src), g.degree(dest)\n",
    "        avg_deg = float(src_deg + dest_deg)/2.0\n",
    "        avg_degrees.append(avg_deg)\n",
    "        \n",
    "        # collect the number of common neighbors\n",
    "        common_neigh.append(len(\n",
    "            set(g.neighbors(src)).intersection(set(g.neighbors(dest)))\n",
    "        ))\n",
    "        \n",
    "        # collect the relative number of common neighbors based on Jaccard coefficient\n",
    "        inters = len(set(g.neighbors(src)).intersection(set(g.neighbors(dest)))) # intersection of neighbors\n",
    "        union = len(set(g.neighbors(src)).union(set(g.neighbors(dest)))) # union of neighbors\n",
    "        jaccard_coeff.append(\n",
    "            (float(inters)/float(union) if union != 0 else 0)\n",
    "        )\n",
    "        \n",
    "        # computational cost is terrible!!!\n",
    "        # collect the betweenness centrality between two nodes\n",
    "        #betw_centrality.append(\n",
    "        #    abs(betweennes[dest] - betweenness[src])\n",
    "        #)\n",
    "    \n",
    "    features = np.array([\n",
    "        temp_diff, \n",
    "        common_auth, \n",
    "        same_journal, \n",
    "        cosines, \n",
    "        overlap_title, \n",
    "        avg_degrees,\n",
    "        common_neigh,\n",
    "        jaccard_coeff\n",
    "        #betw_centrality\n",
    "    ]).T\n",
    "    \n",
    "    if scale:\n",
    "        features = pre.scale(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(filename, pred):\n",
    "    '''\n",
    "    Write prediction result in a submission file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: name of submission file\n",
    "    pred: prediction array\n",
    "    \n",
    "    '''\n",
    "    with open(path_submission + filename, 'wb') as f:\n",
    "        csv_out = csv.writer(f)\n",
    "        csv_out.writerow(['id','category'])\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the citation graph (time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training[:, 2].astype(int) # get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335130 edges among 615512 training instances --> 54.00%\n"
     ]
    }
   ],
   "source": [
    "nb_edges = np.count_nonzero(labels)\n",
    "print('%d edges among %d training instances --> %.2f%%' % (nb_edges, len(labels), 100*nb_edges/len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the graph takes 1.1560 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "edges = [(element[0], element[1]) for element in training if int(element[2]) == 1] # extract all the edges\n",
    "nodes = [element[0] for element in node_info] # extract all the vertices\n",
    "g = build_graph(nodes, edges) # build the graph\n",
    "\n",
    "end = time.time()\n",
    "print('Building the graph takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 27770\n",
      "Number of edges: 335130\n"
     ]
    }
   ],
   "source": [
    "# check the number of vertices and edges\n",
    "print('Number of vertices: %d' % len(g.vs))\n",
    "print('Number of edges: %d' % len(g.es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features (time consuming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prepare some ingredients that serve the computation of features:\n",
    "- TF-IDF matrix, built on the corpus of abstracts\n",
    "- index list containing the ID of each article, to facilitate access to node information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the TF-IDF matrix takes 78.0290 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== corpus is the set of titles + abstracts, apply preprocessing to each article ======#\n",
    "corpus = [preprocess(element[2] + ' ' + element[5], dg_removal=True, sw_removal=True, stemming=True) \n",
    "          for element in node_info]\n",
    "vectorizer = TfidfVectorizer(stop_words='english') # create a TF-IDF vectorizer\n",
    "tfidf = vectorizer.fit_transform(corpus) # TD-IDF matrix of the entire corpus (set of abstracts)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the TF-IDF matrix takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== create an index list, to facilite access to a node by its id ====== #\n",
    "ID = [element[0] for element in node_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'temp_diff', \n",
    "    'common_auth', \n",
    "    'same_journal', \n",
    "    'cosines', \n",
    "    'overlap_title', \n",
    "    'avg_degrees', \n",
    "    'common_neigh', \n",
    "    'jaccard_coeff'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is ready, we start computing features for the training and testing set. The list of features is described as follows, and the computation rule is the same for both training and testing set.\n",
    "\n",
    "| Feature                | Explanation                                                        | Type      | Range   |\n",
    "|:----------------------:|:------------------------------------------------------------------:|:---------:|:-------:|\n",
    "| Temporal difference    | Difference in publication year (absolute value)                    | numerical | $\\ge$ 0 |\n",
    "| Same journal           | Whether two articles are published in the same journal             | binary    | 0, 1    |\n",
    "| Cosine similarity      | Cosine similarity between word vectors of abstracts                | numerical | [0,1]   |\n",
    "| Title overlap          | Number of overlapping words in title                               | numerical | $\\ge$ 0 |\n",
    "| Average degree         | Average degree of two nodes (disregard connected or not            | numerical | $\\ge$ 0 |\n",
    "| Common neighbors       | Number of common neighbors                                         | numercial | $\\ge$ 0 |\n",
    "| Jaccard coefficient    | Link-based Jaccard coefficient                                     | numerical | [0,1]   |\n",
    "| Betweenness centrality | Difference in betweenness centrality of two nodes (absolute value) | numerical | $\\ge$ 0 |\n",
    "\n",
    "This step is highly time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might read already computed features to save time\n",
    "#training_features = np.genfromtxt(path_data + 'training_features.csv', delimiter=',',skip_header=1)\n",
    "#testing_features = np.genfromtxt(path_data + 'testing_features.csv', delimiter=',',skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the training features takes 1655.8490 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== compute training features : (615,521 x 8) ====== #\n",
    "training_features = compute_features(training, g, scale=False)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the training features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the training features takes 87.4310 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== compute testing features : (32,648 x 8) ====== #\n",
    "testing_features = compute_features(testing, g, scale=False)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the training features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test purpose\n",
    "feat = compute_features(training[0:5], g, scale=False)\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Saving features to reload it faster (training_features) ====== #\n",
    "with open(path_data + 'training_features.csv', 'wb') as f:\n",
    "    csv_out = csv.writer(f)\n",
    "    csv_out.writerow(features)\n",
    "    for row in training_features:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Saving features to reload it faster (testing_features) ====== #\n",
    "with open(path_data + 'testing_features.csv', 'wb') as f:\n",
    "    csv_out = csv.writer(f)\n",
    "    csv_out.writerow(features)\n",
    "    for row in testing_features:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Scaling features ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. SVM without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 110.5520 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and predicting with SVM ====== #\n",
    "clf_svm = svm.LinearSVC()\n",
    "clf_svm.fit(training_features, labels)\n",
    "pred_svm = list(clf_svm.predict(testing_features))\n",
    "pred_svm = zip(range(len(testing)), pred_svm)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_06.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. SVM with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC + scaling takes 64.6380 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with SVM and scaled features ====== #\n",
    "clf_svm_scale = svm.LinearSVC()\n",
    "clf_svm_scale.fit(training_features_scale, labels)\n",
    "pred_svm_scale = list(clf_svm_scale.predict(testing_features_scale))\n",
    "pred_svm_scale = zip(range(len(testing)), pred_svm_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_06_scale.csv', pred_svm_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Forest takes 11.2460 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Random Forest ====== #\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(training_features, labels)\n",
    "pred_rf = list(clf_rf.predict(testing_features))\n",
    "pred_rf = zip(range(len(testing)), pred_rf)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Random Forest takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_rf_04.csv', pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 4.0260 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression ====== #\n",
    "clf_lg = LogisticRegression()\n",
    "clf_lg.fit(training_features, labels)\n",
    "pred_lg = list(clf_lg.predict(testing_features))\n",
    "pred_lg = zip(range(len(testing)), pred_lg)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_03.csv', pred_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression + scaling takes 4.0500 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_lg_scale = LogisticRegression()\n",
    "clf_lg_scale.fit(training_features_scale, labels)\n",
    "pred_lg_scale = list(clf_lg_scale.predict(testing_features_scale))\n",
    "pred_lg_scale = zip(range(len(testing)), pred_lg_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_03_scale.csv', pred_lg_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Neural Network without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks takes 29.6230 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_nn = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,40,30,20),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn.fit(training_features, labels)\n",
    "pred_nn = clf_nn.predict(testing_features)\n",
    "pred_nn = zip(range(len(testing)), pred_nn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_04.csv', pred_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks + scaling takes 39.8180 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)\n",
    "\n",
    "clf_nn_scale = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,40,30,20),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn_scale.fit(training_features_scale, labels)\n",
    "pred_nn_scale = clf_nn_scale.predict(testing_features_scale)\n",
    "pred_nn_scale = zip(range(len(testing)), pred_nn_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_04_scale.csv', pred_nn_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Gradient Boosting takes 81.1830 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_gboost = GradientBoostingClassifier(\n",
    "    loss = 'deviance',\n",
    "    n_estimators = 150\n",
    ")\n",
    "clf_gboost.fit(training_features, labels)\n",
    "pred_gboost = clf_gboost.predict(testing_features)\n",
    "pred_gboost = zip(range(len(testing)), pred_gboost)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_gboost_01.csv', pred_gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adaboost takes 108.2860 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_ada = GradientBoostingClassifier(\n",
    "    loss = 'exponential',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_ada.fit(training_features, labels)\n",
    "pred_ada = clf_ada.predict(testing_features)\n",
    "pred_ada = zip(range(len(testing)), pred_ada)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Adaboost takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_ada_02.csv', pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'jaccard_coeff' of importance 0.442\n",
      "Feature 'common_neigh' of importance 0.245\n",
      "Feature 'avg_degrees' of importance 0.140\n",
      "Feature 'cosines' of importance 0.126\n",
      "Feature 'overlap_title' of importance 0.031\n",
      "Feature 'temp_diff' of importance 0.013\n",
      "Feature 'common_auth' of importance 0.002\n",
      "Feature 'same_journal' of importance 0.001\n"
     ]
    }
   ],
   "source": [
    "# ====== compute feature importance ====== #\n",
    "idx = np.argsort(-clf_rf.feature_importances_) # sort the indicator of feature important by decreasing order\n",
    "\n",
    "for i in idx:\n",
    "    print('Feature \\'%s\\' of importance %.3f' % (features[i], clf_rf.feature_importances_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
