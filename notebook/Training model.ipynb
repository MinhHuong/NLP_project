{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model and Issuing predictions (main script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries takes 1.1090 s\n"
     ]
    }
   ],
   "source": [
    "# import time to find consuming steps\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# utility libraries\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import csv\n",
    "from sklearn import preprocessing as pre\n",
    "import re\n",
    "\n",
    "# working with text\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# classifier for classification\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# plotting stuffs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "end = time.time()\n",
    "print('Loading libraries takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset (training, testing, node information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/' # path to the data\n",
    "path_submission = '../submission/' # path to submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading node information takes 0.2350 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read in node informations ====== #\n",
    "with open(path_data + 'node_information.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info = list(reader)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print('Reading node information takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set takes 2.7660 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training data as str ====== #\n",
    "training = np.genfromtxt(path_data + 'training_set.txt', dtype=str)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training set takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing set takes 0.1560 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read testing data as str ====== #\n",
    "testing = np.genfromtxt(path_data + 'testing_set.txt', dtype=str)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading testing set takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(nodes, edges):\n",
    "    '''\n",
    "    Build a graph using igraph library\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nodes: a list of nodes\n",
    "    edges: a list of tuples (source, target)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a graph g\n",
    "    '''\n",
    "    g = ig.Graph(directed=False) # create an undirected graph\n",
    "    g.add_vertices(nodes) # add nodes\n",
    "    g.add_edges(edges) # add edges\n",
    "    \n",
    "    # beware of multiple edges in the graph --> remove all redundant edges between the same pairs of vertices\n",
    "    multiple_edges = [e for e in edges if g.is_multiple(e)]\n",
    "    g.delete_edges(multiple_edges)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Graph.summary of <igraph.Graph object at 0x0000000016D904F8>>\n"
     ]
    }
   ],
   "source": [
    "# a function used to build small graph for test purpose\n",
    "def test_graph():\n",
    "    nodes = ['hello','this','is','my','test']\n",
    "    edges = [(0,1), (0,3), (1,4), (3,2), (4,3)]\n",
    "    gr = build_graph(nodes, edges)\n",
    "    print(gr.summary)\n",
    "    \n",
    "gr = test_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to preprocess text\n",
    "def preprocess(text, dg_removal=True, sw_removal=True, stemming=True):\n",
    "    '''\n",
    "    Preprocess text: stopword removal, stemming, digit removal\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: text on which preprocessing is applied\n",
    "    dg_removal: whether to apply digit removal or not\n",
    "    sw_removal: whether to apply stopword removal or not\n",
    "    stemming: whether to apply stemming or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the text after preprocessing\n",
    "    '''\n",
    "    result = text\n",
    "    \n",
    "    sw = set(nltk.corpus.stopwords.words('english')) # set of stopwords\n",
    "    stemmer = nltk.stem.PorterStemmer() # stemmer\n",
    "    \n",
    "    if dg_removal:\n",
    "        result = re.sub('[0-9]', '', result)\n",
    "    \n",
    "    if sw_removal:\n",
    "        result = ' '.join([token for token in result.split() if token not in sw])\n",
    "        \n",
    "    if stemming:\n",
    "        result = ' '.join([stemmer.stem(token) for token in result.split()])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_authors(authors):\n",
    "    '''\n",
    "    Replace all (...) additional information from the names\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    authors: an author field e.g. \"M. Jinzenji (U. of Tokyo)\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the authors name that is stripped of \"(...)\" e.g. \"M. Jinzenji (U. of Tokyo)\" --> \"M. Jinzenji \"\n",
    "    (some blank, trailing space may be left behind)\n",
    "    '''\n",
    "    \n",
    "    stripped = re.sub('\\(([a-zA-Z0-9\\\\s,\\.\\-\\'\\/&]+)\\)?', '', authors).strip() # remove (...) from author name\n",
    "    \n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(ds, g):\n",
    "    '''\n",
    "    Compute the set of predefined features from the given dataset (training/testing)\n",
    "    - cosine similarity between abstracts (texts already preprocessed)\n",
    "    - temporal difference in term of publication year\n",
    "    - number of common authors\n",
    "    - whether two articles were published in the same journal\n",
    "    - number of overlapped words in preprocessed title\n",
    "    - average degree of both nodes (because orientation is not taken into account)\n",
    "    - number of common neighbors in the graph\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: dataset to compute features from\n",
    "    g: citation graph\n",
    "    betweenness: betweenness centrality of every node (already computed when building graph)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An array of computed features\n",
    "    '''\n",
    "    size = len(ds)\n",
    "    \n",
    "    cosines = np.zeros(size) # feature \"Cosine similarities\", between each abstract (already preprocessed)\n",
    "    temp_diff = [] # feature \"Temporal distance\" i.e. integer values --> numerical feature\n",
    "    common_auth = [] # feature \"Number of common authors\" i.e. integer values --> numerical feature\n",
    "    same_journal = [] # feature \"Same journal\" i.e. binary label 0/1 --> categorical feature\n",
    "    overlap_title = [] # feature \"Overlapping title\" i.e. number of common words in title\n",
    "    avg_degrees = [] # feature \"Average degree\" i.e. the average degree of two nodes participating in the edge\n",
    "    common_neigh = [] # feature \"Common neighbors\" i.e. the citations cited in common between two nodes\n",
    "    jaccard_coeff = [] # feature \"Jaccard coefficient\" i.e. the relative number of common neighbors\n",
    "    same_cluster = [] # feature \"Same cluster\" i.e. to check whether two nodes lie in the same cluster\n",
    "    pr_scores = [] # pagerank score\n",
    "    \n",
    "    #betw_centrality = [] # feature \"Betweenness centrality\" i.e. the difference of betweenness of two connected nodes\n",
    "    \n",
    "    for i in range(size):\n",
    "        src, dest = ds[i][0], ds[i][1] # get the source and dest ID\n",
    "        src_info, dest_info = node_info[ID.index(src)], node_info[ID.index(dest)] # get the associated node information\n",
    "    \n",
    "        # collect the cosine similarity\n",
    "        src_vect, dest_vect = tfidf[ID.index(src)], tfidf[ID.index(dest)] # get the corresponding vector in TD-IDF matrix\n",
    "        cos = cosine_similarity(src_vect, dest_vect) # compute cosine similarity\n",
    "        cosines[i] = cos\n",
    "        \n",
    "        # collect the temporal difference (in absolute value)\n",
    "        temp_diff.append(\n",
    "            abs(int(src_info[1]) - int(dest_info[1]))\n",
    "        )\n",
    "    \n",
    "        # collect the number of common authors\n",
    "        common_auth.append(len(\n",
    "            set(src_info[3].split(',')).intersection(set(dest_info[3].split(',')))\n",
    "        ))\n",
    "    \n",
    "        # collect the information whether the two 2 articles were published in the same journal\n",
    "        same_journal.append(int(\n",
    "            len(src_info[4])>0 and  # journal info of source not null\n",
    "            len(dest_info[4])>0 and # journal info of dest not null\n",
    "            src_info[4] == dest_info[4] # the same journal title\n",
    "        ))\n",
    "        \n",
    "        # collect the number of overlapping words in title\n",
    "        src_title, dest_title = preprocess(src_info[2]).split(), preprocess(dest_info[2]).split()\n",
    "        overlap_title.append(len(\n",
    "            set(src_title).intersection(set(dest_title))\n",
    "        ))\n",
    "        \n",
    "        # collect the difference in degrees\n",
    "        src_deg, dest_deg = g.degree(src), g.degree(dest)\n",
    "        avg_deg = float(src_deg + dest_deg)/2.0\n",
    "        avg_degrees.append(avg_deg)\n",
    "        \n",
    "        # collect the number of common neighbors\n",
    "        common_neigh.append(len(\n",
    "            set(g.neighbors(src)).intersection(set(g.neighbors(dest)))\n",
    "        ))\n",
    "        \n",
    "        # collect the relative number of common neighbors based on Jaccard coefficient\n",
    "        inters = len(set(g.neighbors(src)).intersection(set(g.neighbors(dest)))) # intersection of neighbors\n",
    "        union = len(set(g.neighbors(src)).union(set(g.neighbors(dest)))) # union of neighbors\n",
    "        jaccard_coeff.append(\n",
    "            (float(inters)/float(union) if union != 0 else 0)\n",
    "        )\n",
    "        \n",
    "        # collect the information of same cluster\n",
    "        same_cluster.append(int(\n",
    "            node_cluster[src] == node_cluster[dest]\n",
    "        ))\n",
    "        \n",
    "        # collect the pagerank score (average of pagerank of two nodes)\n",
    "        pr_src, pr_dest = pg[ID.index(src)], pg[ID.index(dest)]\n",
    "        pr_scores.append(\n",
    "            float(pr_src+pr_dest)*10000/2.0\n",
    "        )\n",
    "        \n",
    "        # computational cost is terrible!!!\n",
    "        # collect the betweenness centrality between two nodes\n",
    "        #betw_centrality.append(\n",
    "        #    abs(betweennes[dest] - betweenness[src])\n",
    "        #)\n",
    "    \n",
    "    features = np.array([\n",
    "        temp_diff, \n",
    "        common_auth, \n",
    "        same_journal, \n",
    "        cosines, \n",
    "        overlap_title, \n",
    "        avg_degrees,\n",
    "        common_neigh,\n",
    "        jaccard_coeff,\n",
    "        same_cluster,\n",
    "        pr_scores\n",
    "        #betw_centrality\n",
    "    ]).T\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(filename, pred):\n",
    "    '''\n",
    "    Write prediction result in a submission file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: name of submission file\n",
    "    pred: prediction array\n",
    "    \n",
    "    '''\n",
    "    with open(path_submission + filename, 'wb') as f:\n",
    "        csv_out = csv.writer(f)\n",
    "        csv_out.writerow(['id','category'])\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the citation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training[:, 2].astype(int) # get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335130 edges (before processing) among 615512 training instances --> 54.00%\n"
     ]
    }
   ],
   "source": [
    "nb_edges = np.count_nonzero(labels)\n",
    "print('%d edges (before processing) among %d training instances --> %.2f%%' % (nb_edges, len(labels), 100*nb_edges/len(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph (and remove multiple edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the graph takes 23.6430 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "edges = [(element[0], element[1]) for element in training if int(element[2]) == 1] # extract all the edges\n",
    "nodes = [element[0] for element in node_info] # extract all the vertices\n",
    "g = build_graph(nodes, edges) # build the graph\n",
    "\n",
    "end = time.time()\n",
    "print('Building the graph takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 27770\n",
      "Number of edges (after multiple edges removal): 334690\n"
     ]
    }
   ],
   "source": [
    "# check the number of vertices and edges\n",
    "print('Number of vertices: %d' % len(g.vs))\n",
    "print('Number of edges (after multiple edges removal): %d' % len(g.es))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding community takes 99.3380 s\n"
     ]
    }
   ],
   "source": [
    "# ====== find the community structures ====== #\n",
    "start = time.time()\n",
    "\n",
    "dendogram = g.community_fastgreedy()\n",
    "clusters_g = dendogram.as_clustering()\n",
    "subg = clusters_g.subgraphs()\n",
    "\n",
    "end = time.time()\n",
    "print('Finding community takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping of (node : #cluster) for easy access when computing features\n",
    "node_cluster = dict(zip(nodes, [0]*len(nodes)))\n",
    "\n",
    "idx = 1 # assign a number for each distinct cluster\n",
    "for sb in subg:\n",
    "    for v in sb.vs:\n",
    "        node_cluster[v['name']] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing features (time consuming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prepare some ingredients that serve the computation of features:\n",
    "- TF-IDF matrix, built on the corpus of abstracts\n",
    "- index list containing the ID of each article, to facilitate access to node information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the TF-IDF matrix takes 63.4280 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== corpus is the set of titles + abstracts, apply preprocessing to each article ======#\n",
    "corpus = [preprocess(element[2] + ' ' + element[5], dg_removal=True, sw_removal=True, stemming=True) \n",
    "          for element in node_info]\n",
    "vectorizer = TfidfVectorizer(stop_words='english') # create a TF-IDF vectorizer\n",
    "tfidf = vectorizer.fit_transform(corpus) # TD-IDF matrix of the entire corpus (set of abstracts)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the TF-IDF matrix takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== create an index list, to facilite access to a node by its id ====== #\n",
    "ID = [element[0] for element in node_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'temp_diff', \n",
    "    'common_auth', \n",
    "    'same_journal', \n",
    "    'cosines', \n",
    "    'overlap_title', \n",
    "    'diff_degrees', \n",
    "    'common_neigh', \n",
    "    'jaccard_coeff',\n",
    "    'same_cluster', \n",
    "    'page_rank'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is ready, we start computing features for the training and testing set. The list of features is described as follows, and the computation rule is the same for both training and testing set.\n",
    "\n",
    "| Feature                | Explanation                                                        | Type      | Range   |\n",
    "|:----------------------:|:------------------------------------------------------------------:|:---------:|:-------:|\n",
    "| Temporal difference    | Difference in publication year (absolute value)                    | numerical | $\\ge$ 0 |\n",
    "| Same journal           | Whether two articles are published in the same journal             | binary    | 0, 1    |\n",
    "| Cosine similarity      | Cosine similarity between word vectors of abstracts                | numerical | [0,1]   |\n",
    "| Title overlap          | Number of overlapping words in title                               | numerical | $\\ge$ 0 |\n",
    "| Degree difference      | Difference in measure of degrees of two nodes (absolute value)     | numerical | $\\ge$ 0 |\n",
    "| Common neighbors       | Number of common neighbors                                         | numercial | $\\ge$ 0 |\n",
    "| Jaccard coefficient    | Link-based Jaccard coefficient                                     | numerical | [0,1]   |\n",
    "| Same cluster           | Check whether two nodes are in the same cluster                    | binary    | [0,1]   |\n",
    "| Betweenness centrality | Difference in betweenness centrality of two nodes (absolute value) | numerical | $\\ge$ 0 |\n",
    "\n",
    "This step is highly time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might read already computed features to save time\n",
    "#training_features = np.genfromtxt(path_data + 'training_features.csv', delimiter=',',skip_header=1)\n",
    "#testing_features = np.genfromtxt(path_data + 'testing_features.csv', delimiter=',',skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing author field (not sure if this is necessary though)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the list of authors, we find out that some records are not 'correctly' formatted, e.g., even though L.D. Paniak (Princeton University) and \"L.D. Paniak (Princeton)\" are the same person, only splitting the author field by ',' as separator would consider this two formats different, hence causing information loss. Before proceeding to compute features, we need to preprocess the author field first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group_authors = [group[3] for group in node_info] # read in all authors\n",
    "# authors = []\n",
    "\n",
    "# # TODO: also modify the details of authors in node_info (remove (..) and strip)\n",
    "# for group in group_authors:\n",
    "#     if group != '': # some author field is left empty\n",
    "#         #stripped = re.sub('\\(([a-zA-Z0-9\\\\s,\\.\\-\\'\\/&]+)\\)?', '', group).strip() # remove (...) from author name\n",
    "#         stripped = preprocess_authors(group).strip()\n",
    "#         for indi in stripped.split(','):\n",
    "#             indi = indi.strip()\n",
    "#             if indi != '':\n",
    "#                 authors.append(indi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Individual authors: %d' % len(authors))\n",
    "\n",
    "# uni_authors, count = np.unique(authors, return_counts=True)\n",
    "# author_score = dict(zip(uni_authors, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the PageRank index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding page rank of all nodes in the graph takes 0.3280s\n"
     ]
    }
   ],
   "source": [
    "# ====== compute page rank of each node in the entire graph ====== #\n",
    "start = time.time()\n",
    "\n",
    "pg = g.pagerank()\n",
    "\n",
    "end = time.time()\n",
    "print('Finding page rank of all nodes in the graph takes %.4fs' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing training and testing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the training features takes 1854.1320\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== compute training features : (615,521 x 10) ====== #\n",
    "training_features = compute_features(training, g)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the training features takes %.4f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the testing features takes 98.0200 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== compute testing features : (32,648 x 10) ====== #\n",
    "testing_features = compute_features(testing, g)\n",
    "\n",
    "end = time.time()\n",
    "print('Computing the testing features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 1.99966215e-01,\n",
       "        2.00000000e+00, 9.00000000e+00, 1.00000000e+00, 5.88235294e-02,\n",
       "        1.00000000e+00, 2.13292993e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.43694475e-02,\n",
       "        1.00000000e+00, 1.13000000e+02, 2.00000000e+01, 9.70873786e-02,\n",
       "        1.00000000e+00, 9.25094418e-01],\n",
       "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.05371115e-02,\n",
       "        0.00000000e+00, 3.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.26364844e-01],\n",
       "       [4.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.93784382e-02,\n",
       "        0.00000000e+00, 1.70000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 2.04888212e-01],\n",
       "       [5.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.85264277e-02,\n",
       "        0.00000000e+00, 1.55000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 2.32628234e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test purpose\n",
    "feat = compute_features(training[0:5], g)\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Saving features to reload it faster (training_features) ====== #\n",
    "with open(path_data + 'training_features.csv', 'wb') as f:\n",
    "    csv_out = csv.writer(f)\n",
    "    csv_out.writerow(features)\n",
    "    for row in training_features:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Saving features to reload it faster (testing_features) ====== #\n",
    "with open(path_data + 'testing_features.csv', 'wb') as f:\n",
    "    csv_out = csv.writer(f)\n",
    "    csv_out.writerow(features)\n",
    "    for row in testing_features:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Scaling features ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. SVM without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 110.0520 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and predicting with SVM ====== #\n",
    "clf_svm = svm.LinearSVC()\n",
    "clf_svm.fit(training_features, labels)\n",
    "pred_svm = list(clf_svm.predict(testing_features))\n",
    "pred_svm = zip(range(len(testing)), pred_svm)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_08.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. SVM with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC + scaling takes 67.3250 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with SVM and scaled features ====== #\n",
    "clf_svm_scale = svm.LinearSVC()\n",
    "clf_svm_scale.fit(training_features_scale, labels)\n",
    "pred_svm_scale = list(clf_svm_scale.predict(testing_features_scale))\n",
    "pred_svm_scale = zip(range(len(testing)), pred_svm_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_08_scale.csv', pred_svm_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Forest takes 14.4230 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Random Forest ====== #\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(training_features, labels)\n",
    "pred_rf = list(clf_rf.predict(testing_features))\n",
    "pred_rf = zip(range(len(testing)), pred_rf)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Random Forest takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_rf_06.csv', pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 5.5160 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression ====== #\n",
    "clf_lg = LogisticRegression()\n",
    "clf_lg.fit(training_features, labels)\n",
    "pred_lg = list(clf_lg.predict(testing_features))\n",
    "pred_lg = zip(range(len(testing)), pred_lg)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_05.csv', pred_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression + scaling takes 5.7820 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_lg_scale = LogisticRegression()\n",
    "clf_lg_scale.fit(training_features_scale, labels)\n",
    "pred_lg_scale = list(clf_lg_scale.predict(testing_features_scale))\n",
    "pred_lg_scale = zip(range(len(testing)), pred_lg_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_05_scale.csv', pred_lg_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Neural Network without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks takes 92.6970 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_nn = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,30,20),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn.fit(training_features, labels)\n",
    "pred_nn = clf_nn.predict(testing_features)\n",
    "pred_nn = zip(range(len(testing)), pred_nn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_06.csv', pred_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks + scaling takes 54.7090 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)\n",
    "\n",
    "clf_nn_scale = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,30,20),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn_scale.fit(training_features_scale, labels)\n",
    "pred_nn_scale = clf_nn_scale.predict(testing_features_scale)\n",
    "pred_nn_scale = zip(range(len(testing)), pred_nn_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_06_scale.csv', pred_nn_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Gradient Boosting takes 157.5080 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_gboost = GradientBoostingClassifier(\n",
    "    loss = 'deviance',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_gboost.fit(training_features, labels)\n",
    "pred_gboost = clf_gboost.predict(testing_features)\n",
    "pred_gboost = zip(range(len(testing)), pred_gboost)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_gboost_03.csv', pred_gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adaboost takes 153.1410 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_ada = GradientBoostingClassifier(\n",
    "    loss = 'exponential',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_ada.fit(training_features, labels)\n",
    "pred_ada = clf_ada.predict(testing_features)\n",
    "pred_ada = zip(range(len(testing)), pred_ada)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Adaboost takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_ada_04.csv', pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'jaccard_coeff' of importance 0.445\n",
      "Feature 'common_neigh' of importance 0.302\n",
      "Feature 'cosines' of importance 0.104\n",
      "Feature 'diff_degrees' of importance 0.077\n",
      "Feature 'page_rank' of importance 0.041\n",
      "Feature 'same_cluster' of importance 0.012\n",
      "Feature 'temp_diff' of importance 0.010\n",
      "Feature 'overlap_title' of importance 0.005\n",
      "Feature 'common_auth' of importance 0.002\n",
      "Feature 'same_journal' of importance 0.002\n"
     ]
    }
   ],
   "source": [
    "# ====== compute feature importance ====== #\n",
    "idx = np.argsort(-clf_rf.feature_importances_) # sort the indicator of feature important by decreasing order\n",
    "\n",
    "for i in idx:\n",
    "    print('Feature \\'%s\\' of importance %.3f' % (features[i], clf_rf.feature_importances_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
