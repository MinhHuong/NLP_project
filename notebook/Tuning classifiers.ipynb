{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries takes 0.0003 s\n"
     ]
    }
   ],
   "source": [
    "# import time to find consuming steps\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# utility libraries\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn import preprocessing as pre\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# classifier for classification\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import recall_score, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "\n",
    "end = time.time()\n",
    "print('Loading libraries takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset (training, testing, node information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/' # path to the data\n",
    "path_submission = '../submission/' # path to submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set & extracting labels takes 2.9194 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training data as str ====== #\n",
    "training = np.genfromtxt(path_data + 'training_set.txt', dtype=str)\n",
    "\n",
    "# ====== extract labels ====== #\n",
    "labels = training[:, 2].astype(int) # get the labels\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training set & extracting labels takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training features takes 10.3715 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training features ====== #\n",
    "orig_training_features = np.genfromtxt(path_data + 'training_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing features takes 0.5168 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read testing features as str ====== #\n",
    "orig_testing_features = np.genfromtxt(path_data + 'testing_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading testing features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 15)\n",
      "Labels: (615512,)\n",
      "Testing features: (32648, 15)\n"
     ]
    }
   ],
   "source": [
    "print('Training features:', orig_training_features.shape)\n",
    "print('Labels:', labels.shape)\n",
    "print('Testing features:', orig_testing_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking up some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we might need to remove some features read from file. Here, we remove features by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_features = [\n",
    "    'temporal_difference', # 0\n",
    "    'common_authors', # 1\n",
    "    'same_journal', # 2\n",
    "    'cosine_sim', # 3\n",
    "    'overlapping_title', # 4\n",
    "    'max_degrees', # 5\n",
    "    'common_neighbors', # 6\n",
    "    'jaccard_coefficient', # 7\n",
    "    'max_pagerank', # 8\n",
    "    'max_betweenness', # 9\n",
    "    'in_kcore', # 10\n",
    "    'adamic_adar', # 11\n",
    "    'katz_index', # 12\n",
    "    'cosine_sim_w2v', # 13\n",
    "    'katz_linkpred' # 14\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 13)\n"
     ]
    }
   ],
   "source": [
    "# remove very features before training\n",
    "to_remove = [14,13]\n",
    "training_features = np.nan_to_num(np.delete(orig_training_features, to_remove, 1))\n",
    "testing_features = np.nan_to_num(np.delete(orig_testing_features, to_remove, 1))\n",
    "features = np.delete(orig_features, to_remove)\n",
    "\n",
    "print('Training features:', training_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [[ 0.00000000e+00  0.00000000e+00  1.00000000e+00  1.99966215e-01\n",
      "   2.00000000e+00  1.20000000e+01  1.00000000e+00  5.88235294e-02\n",
      "  -1.04952174e+01  1.05093708e+01  0.00000000e+00  5.13898342e-01\n",
      "  -5.58044870e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00  0.00000000e+00  6.43694475e-02\n",
      "   1.00000000e+00  1.47000000e+02  2.00000000e+01  9.70873786e-02\n",
      "  -9.04507102e+00  1.13932537e+01  1.00000000e+00  4.32036615e+00\n",
      "  -4.21648550e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00  0.00000000e+00  2.05371115e-02\n",
      "   0.00000000e+00  5.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.10308202e+01  9.53921731e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.64652461e+00]\n",
      " [ 4.00000000e+00  0.00000000e+00  0.00000000e+00  5.93784382e-02\n",
      "   0.00000000e+00  2.00000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -1.06715646e+01  8.04019582e+00  5.00000000e-01  0.00000000e+00\n",
      "  -5.25171866e+00]\n",
      " [ 5.00000000e+00  0.00000000e+00  0.00000000e+00  9.85264277e-02\n",
      "   0.00000000e+00  2.40000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -1.04743869e+01  9.38724288e+00  5.00000000e-01  0.00000000e+00\n",
      "  -5.36014155e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.95819232e-01\n",
      "   0.00000000e+00  3.80000000e+01  1.40000000e+01  2.37288136e-01\n",
      "  -1.02789087e+01  8.87265376e+00  1.00000000e+00  3.17502987e+00\n",
      "  -4.96955029e+00]\n",
      " [ 4.00000000e+00  1.00000000e+00  0.00000000e+00  1.87225690e-01\n",
      "   0.00000000e+00  7.39000000e+02  1.20000000e+01  1.52284264e-02\n",
      "  -7.28060674e+00  1.59955066e+01  1.00000000e+00  2.46874101e+00\n",
      "  -2.88068326e+00]\n",
      " [ 7.00000000e+00  0.00000000e+00  0.00000000e+00  8.62705384e-02\n",
      "   1.00000000e+00  8.60000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -9.25626085e+00  1.26364092e+01  5.00000000e-01  0.00000000e+00\n",
      "  -4.86388004e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  4.18143621e-02\n",
      "   0.00000000e+00  1.00000000e+02  5.00000000e+00  3.67647059e-02\n",
      "  -9.19986647e+00  1.30247650e+01  1.00000000e+00  9.42862303e-01\n",
      "  -4.29294528e+00]\n",
      " [ 8.00000000e+00  0.00000000e+00  0.00000000e+00  6.04475137e-02\n",
      "   0.00000000e+00  3.00000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -9.55846355e+00  1.19906480e+01  0.00000000e+00  0.00000000e+00\n",
      "  -5.46850804e+00]]\n",
      "Testing: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.18040092e-01\n",
      "   0.00000000e+00  5.90000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -9.71123221e+00  1.25886650e+01  1.00000000e+00  0.00000000e+00\n",
      "  -4.69918791e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00  0.00000000e+00  3.07862648e-01\n",
      "   2.00000000e+00  3.02000000e+02  2.40000000e+01  7.43034056e-02\n",
      "  -8.05014677e+00  1.47780702e+01  1.00000000e+00  5.37797275e+00\n",
      "  -3.80632847e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00  1.00000000e+00  2.07538045e-01\n",
      "   1.00000000e+00  7.39000000e+02  5.90000000e+01  6.53377630e-02\n",
      "  -7.28060674e+00  1.59955066e+01  1.00000000e+00  1.50536117e+01\n",
      "  -2.88068326e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  1.61124069e-01\n",
      "   1.00000000e+00  6.50000000e+01  2.10000000e+01  2.21052632e-01\n",
      "  -9.78108665e+00  1.12049512e+01  1.00000000e+00  4.89942438e+00\n",
      "  -4.78584888e+00]\n",
      " [ 5.00000000e+00  0.00000000e+00  0.00000000e+00  3.18244526e-01\n",
      "   0.00000000e+00  1.50000000e+02  0.00000000e+00  0.00000000e+00\n",
      "  -8.84688464e+00  1.31624585e+01  5.00000000e-01  0.00000000e+00\n",
      "  -4.22347698e+00]\n",
      " [ 4.00000000e+00  1.00000000e+00  0.00000000e+00  3.46687156e-02\n",
      "   0.00000000e+00  3.50000000e+01  0.00000000e+00  0.00000000e+00\n",
      "  -1.03515694e+01  1.02670683e+01  5.00000000e-01  0.00000000e+00\n",
      "  -4.97580013e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.49026627e-02\n",
      "   1.00000000e+00  4.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.11370020e+01  5.53651846e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.65542043e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00  1.00000000e+00  1.99910478e-01\n",
      "   1.00000000e+00  4.20000000e+01  6.00000000e+00  1.05263158e-01\n",
      "  -9.81535402e+00  1.10795443e+01  1.00000000e+00  1.46868886e+00\n",
      "  -5.30505257e+00]\n",
      " [ 7.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  7.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.09464534e+01  7.44026286e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.61555170e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  3.28366499e-01\n",
      "   1.00000000e+00  1.30000000e+01  4.00000000e+00  1.90476190e-01\n",
      "  -1.08153264e+01  8.02905778e+00  0.00000000e+00  1.27898053e+00\n",
      "  -5.50044342e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('Training:', training_features[0:10])\n",
    "print('Testing:', testing_features[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(filename, pred):\n",
    "    '''\n",
    "    Write prediction result in a submission file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: name of submission file\n",
    "    pred: prediction array\n",
    "    \n",
    "    '''\n",
    "    with open(path_submission + filename, 'w', newline='') as f:\n",
    "        csv_out = csv.writer(f)\n",
    "        csv_out.writerow(['id','category'])\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Scaling features ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_size = len(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation for: 0\n",
      "Running cross-validation for: 1\n",
      "Running cross-validation for: 2\n",
      "Tuning parameters for SVM takes 1768.1033 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# a list of svm classifiers with differenet settings\n",
    "clfs_svm = [\n",
    "    svm.LinearSVC(penalty='l2', loss='squared_hinge', C=1.0, fit_intercept=True),\n",
    "    svm.LinearSVC(penalty='l2', loss='hinge', C=1.0, fit_intercept=True),\n",
    "    svm.LinearSVC(penalty='l1', loss='squared_hinge', C=1.0, fit_intercept=True, dual=False)\n",
    "]\n",
    "\n",
    "# check for best settings (without tuning C)\n",
    "tune_svm_scores = []\n",
    "for index, clf in enumerate(clfs_svm):\n",
    "    print('Running cross-validation for:', index)\n",
    "    tune_svm_scores.append(cross_val_score(clf, training_features_scale, labels, cv=10, scoring='f1'))\n",
    "    \n",
    "end = time.time()\n",
    "print('Tuning parameters for SVM takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96474375 0.96784078 0.96441065]\n",
      "Best setting for SVM: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(tune_svm_scores,axis=1))\n",
    "best_clf_svm = clfs_svm[np.argmax(np.mean(tune_svm_scores,axis=1))]\n",
    "print('Best setting for SVM:', best_clf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 11.3090 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with SVM and scaled features ====== #\n",
    "best_clf_svm.fit(training_features_scale, labels)\n",
    "pred_svm = list(best_clf_svm.predict(testing_features_scale))\n",
    "pred_svm = zip(range(testing_size), pred_svm)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('tuned_submission_svm_01.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM: 0.9678 (+/- 0.0005)\n"
     ]
    }
   ],
   "source": [
    "svm_scores = cross_val_score(best_clf_svm, training_features_scale, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with SVM: %0.4f (+/- %0.4f)\" % (svm_scores.mean(), svm_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-A. SVM without scaling (do not use, always scale for better performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 4.2013 s\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # ====== training and predicting with SVM ====== #\n",
    "# clf_svm = svm.LinearSVC(dual=False, C=1.0)\n",
    "# clf_svm.fit(training_features, labels)\n",
    "# pred_svm = list(clf_svm.predict(testing_features))\n",
    "# pred_svm = zip(range(len(testing_features)), pred_svm)\n",
    "\n",
    "# end = time.time()\n",
    "# print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission('submission_svm_11.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM: 0.9650 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "# svm_scores = cross_val_score(clf_svm, training_features, labels, cv=5, scoring='f1')\n",
    "# print(\"F1-score with SVM: %0.4f (+/- %0.4f)\" % (svm_scores.mean(), svm_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-B. SVM with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC + scaling takes 1.8097 s\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # ====== training and prediction with SVM and scaled features ====== #\n",
    "# clf_svm_scale = svm.LinearSVC(dual=False, C=1.0)\n",
    "# clf_svm_scale.fit(training_features_scale, labels)\n",
    "# pred_svm_scale = list(clf_svm_scale.predict(testing_features_scale))\n",
    "# pred_svm_scale = zip(range(testing_size), pred_svm_scale)\n",
    "\n",
    "# end = time.time()\n",
    "# print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission('submission_svm_16_scale.csv', pred_svm_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM scaling: 0.9650 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "# svm_scale_scores = cross_val_score(clf_svm_scale, training_features, labels, cv=5, scoring='f1')\n",
    "# print(\"F1-score with SVM scaling: %0.4f (+/- %0.4f)\" % (svm_scale_scores.mean(), svm_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Forest takes 6.5426 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Random Forest ====== #\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(training_features, labels)\n",
    "pred_rf = list(clf_rf.predict(testing_features))\n",
    "pred_rf = zip(range(testing_size), pred_rf)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Random Forest takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_rf_11.csv', pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_val_score(clf_rf, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of RandomForest: %0.4f (+/- %0.4f)\" % (rf_scores.mean(), rf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation for: 0\n",
      "Running cross-validation for: 1\n",
      "Running cross-validation for: 2\n",
      "Tuning parameters for Logistic Regression takes 358.0291 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# a list of svm classifiers with differenet settings\n",
    "clfs_logreg = [\n",
    "    LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "    LogisticRegression(penalty='l2', solver='newton-cg'),\n",
    "    LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "    #LogisticRegression(penalty='l1', solver='saga', max_iter=5000) #takes too long\n",
    "]\n",
    "\n",
    "# check for best settings (without tuning C)\n",
    "tune_logreg_scores = []\n",
    "for index, clf in enumerate(clfs_logreg):\n",
    "    print('Running cross-validation for:', index)\n",
    "    tune_logreg_scores.append(cross_val_score(clf, training_features_scale, labels, cv=10, scoring='f1'))\n",
    "    \n",
    "end = time.time()\n",
    "print('Tuning parameters for Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96163912 0.96170016 0.96169857]\n",
      "Best setting for Logistic Regression: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(tune_logreg_scores, axis=1))\n",
    "best_clf_logreg = clfs_logreg[np.argmax(np.mean(tune_logreg_scores,axis=1))]\n",
    "print('Best setting for Logistic Regression:', best_clf_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 17.7848 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression and scaled features ====== #\n",
    "best_clf_logreg.fit(training_features_scale, labels)\n",
    "pred_logreg = list(best_clf_logreg.predict(testing_features_scale))\n",
    "pred_logreg = zip(range(testing_size), pred_logreg)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('tuned_submission_lg_02.csv', pred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.9616 (+/- 0.0006)\n"
     ]
    }
   ],
   "source": [
    "logreg_scores = cross_val_score(best_clf_logreg, training_features_scale, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of Logistic Regression: %0.4f (+/- %0.4f)\" % (logreg_scores.mean(), logreg_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 7.7782 s\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # ====== training and prediction with Logistic Regression ====== #\n",
    "# clf_lg = LogisticRegression()\n",
    "# clf_lg.fit(training_features, labels)\n",
    "# pred_lg = list(clf_lg.predict(testing_features))\n",
    "# pred_lg = zip(range(testing_size), pred_lg)\n",
    "\n",
    "# end = time.time()\n",
    "# print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission('submission_lg_07.csv', pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.9669 (+/- 0.0008)\n"
     ]
    }
   ],
   "source": [
    "# lg_scores = cross_val_score(clf_lg, training_features, labels, cv=5, scoring='f1')\n",
    "# print(\"Accuracy of Logistic Regression: %0.4f (+/- %0.4f)\" % (lg_scores.mean(), lg_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression + scaling takes 2.5854 s\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "# clf_lg_scale = LogisticRegression()\n",
    "# clf_lg_scale.fit(training_features_scale, labels)\n",
    "# pred_lg_scale = list(clf_lg_scale.predict(testing_features_scale))\n",
    "# pred_lg_scale = zip(range(testing_size), pred_lg_scale)\n",
    "\n",
    "# end = time.time()\n",
    "# print('Training with Logistic Regression + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission('submission_lg_07_scale.csv', pred_lg_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with Logistic Regression + scaling: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# lg_scale_scores = cross_val_score(clf_lg_scale, training_features_scale, labels, cv=5, scoring='f1')\n",
    "# print(\"F1-score with Logistic Regression + scaling: %0.4f (+/- %0.4f)\" % (lg_scale_scores.mean(), lg_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Neural Network without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks takes 149.1154 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn.fit(training_features, labels)\n",
    "pred_nn = clf_nn.predict(testing_features)\n",
    "pred_nn = zip(range(testing_size), pred_nn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_26.csv', pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Neural Network: 0.9999 (+/- 0.0001)\n",
      "Cross validation evaluation on Neural Network takes 315.9771 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# cross validation\n",
    "nn_scores = cross_val_score(clf_nn, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score of Neural Network: %0.4f (+/- %0.4f)\" % (nn_scores.mean(), nn_scores.std() * 2))\n",
    "\n",
    "end = time.time()\n",
    "print('Cross validation evaluation on Neural Network takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks + scaling takes 50.3232 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn_scale = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn_scale.fit(training_features_scale, labels)\n",
    "pred_nn_scale = clf_nn_scale.predict(testing_features_scale)\n",
    "pred_nn_scale = zip(range(testing_size), pred_nn_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_10_scale.csv', pred_nn_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Neural Network + scaling: 0.9978 (+/- 0.0022)\n"
     ]
    }
   ],
   "source": [
    "nn_scale_scores = cross_val_score(clf_nn_scale, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score of Neural Network + scaling: %0.4f (+/- %0.4f)\" % (nn_scale_scores.mean(), nn_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning stuffs to find best number of estimators\n",
    "start = time.time()\n",
    "\n",
    "# a list of svm classifiers with differenet settings\n",
    "clfs_gb = [\n",
    "    GradientBoostingClassifier(n_estimators=100),\n",
    "    GradientBoostingClassifier(n_estimators=150),\n",
    "    GradientBoostingClassifier(n_estimators=200),\n",
    "    GradientBoostingClassifier(n_estimators=250),\n",
    "    GradientBoostingClassifier(n_estimators=300)\n",
    "]\n",
    "\n",
    "# check for best settings (without tuning C)\n",
    "tune_gb_scores = []\n",
    "for index, clf in enumerate(clfs_gb):\n",
    "    print('Running cross-validation for:', index)\n",
    "    tune_gb_scores.append(cross_val_score(clf, training_features_scale, labels, cv=10, scoring='f1'))\n",
    "    \n",
    "end = time.time()\n",
    "print('Tuning parameters for Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(tune_gb_scores, axis=1))\n",
    "best_clf_gb = clfs_gb[np.argmax(np.mean(tune_gb_scores,axis=1))]\n",
    "print('Best setting for Gradient Boosting:', best_clf_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 17.7848 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression and scaled features ====== #\n",
    "best_clf_gb.fit(training_features_scale, labels)\n",
    "pred_gb = list(best_clf_gb.predict(testing_features_scale))\n",
    "pred_gb = zip(range(testing_size), pred_gb)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('tuned_submission_gb_01.csv', pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM: 0.9678 (+/- 0.0005)\n"
     ]
    }
   ],
   "source": [
    "gb_scores = cross_val_score(best_gb_svm, training_features_scale, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with Gradient Boosting: %0.4f (+/- %0.4f)\" % (gb_scores.mean(), gb_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Gradient Boosting takes 35.0845 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_gboost = GradientBoostingClassifier(\n",
    "    loss = 'deviance',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_gboost.fit(training_features, labels)\n",
    "pred_gboost = clf_gboost.predict(testing_features)\n",
    "pred_gboost = zip(range(testing_size), pred_gboost)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_gboost_05.csv', pred_gboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with Gradient Boosting: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "gd_scores = cross_val_score(clf_gboost, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with Gradient Boosting: %0.4f (+/- %0.4f)\" % (gd_scores.mean(), gd_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adaboost takes 47.4125 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_ada = GradientBoostingClassifier(\n",
    "    loss = 'exponential',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_ada.fit(training_features, labels)\n",
    "pred_ada = clf_ada.predict(testing_features)\n",
    "pred_ada = zip(range(testing_size), pred_ada)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Adaboost takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_ada_05.csv', pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with AdaBoost: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "ada_scores = cross_val_score(clf_ada, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with AdaBoost: %0.4f (+/- %0.4f)\" % (ada_scores.mean(), ada_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating to pick up the optimal number of neighbors takes 4485.4285 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, labels, test_size=0.35, random_state=42)\n",
    "\n",
    "myList = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "\n",
    "end = time.time()\n",
    "print('Cross-validating to pick up the optimal number of neighbors takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 11\n"
     ]
    }
   ],
   "source": [
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "_neighbors = list(neighbors)\n",
    "optimal_k = _neighbors[np.argmin(MSE)]\n",
    "print('The optimal number of neighbors is %d' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with k-nearest neighbors takes 44.9709 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training & predicting with k-Neareat Neighbors ====== #\n",
    "clf_knn = KNeighborsClassifier(\n",
    "    n_neighbors = optimal_k\n",
    ")\n",
    "clf_knn.fit(training_features, labels)\n",
    "pred_knn = clf_knn.predict(testing_features)\n",
    "pred_knn = zip(range(testing_size), pred_knn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with k-nearest neighbors takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_knn_01.csv', pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with K-NearestNeighbors: 0.9588 (+/- 0.0008)\n"
     ]
    }
   ],
   "source": [
    "knn_scores = cross_val_score(clf_knn, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with K-NearestNeighbors: %0.4f (+/- %0.4f)\" % (knn_scores.mean(), knn_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'common_neighbors' of importance 0.22939\n",
      "Feature 'jaccard_coefficient' of importance 0.20892\n",
      "Feature 'adamic_adar' of importance 0.20253\n",
      "Feature 'katz_linkpred' of importance 0.18249\n",
      "Feature 'cosine_sim' of importance 0.11278\n",
      "Feature 'max_pagerank' of importance 0.02163\n",
      "Feature 'max_degrees' of importance 0.02016\n",
      "Feature 'katz_index' of importance 0.00961\n",
      "Feature 'max_betweenness' of importance 0.00417\n",
      "Feature 'overlapping_title' of importance 0.00357\n",
      "Feature 'in_kcore' of importance 0.00271\n",
      "Feature 'cosine_sim_w2v' of importance 0.00114\n",
      "Feature 'temporal_difference' of importance 0.00057\n",
      "Feature 'common_authors' of importance 0.00024\n",
      "Feature 'same_journal' of importance 0.00008\n"
     ]
    }
   ],
   "source": [
    "# ====== compute feature importance ====== #\n",
    "clf_rf.fit(np.nan_to_num(orig_training_features), labels)\n",
    "idx = np.argsort(-clf_rf.feature_importances_) # sort the indicator of feature important by decreasing order\n",
    "\n",
    "for i in idx:\n",
    "    print('Feature \\'%s\\' of importance %.5f' % (orig_features[i], clf_rf.feature_importances_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
