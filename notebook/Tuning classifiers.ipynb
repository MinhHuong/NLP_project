{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries takes 1.1800 s\n"
     ]
    }
   ],
   "source": [
    "# import time to find consuming steps\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# utility libraries\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn import preprocessing as pre\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# classifier for classification\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import recall_score, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "\n",
    "end = time.time()\n",
    "print('Loading libraries takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset (training, testing, node information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/' # path to the data\n",
    "path_submission = '../submission/' # path to submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set & extracting labels takes 2.8691 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training data as str ====== #\n",
    "training = np.genfromtxt(path_data + 'training_set.txt', dtype=str)\n",
    "\n",
    "# ====== extract labels ====== #\n",
    "labels = training[:, 2].astype(int) # get the labels\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training set & extracting labels takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training features takes 8.0128 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training features ====== #\n",
    "orig_training_features = np.genfromtxt(path_data + 'training_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing features takes 0.4422 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read testing features as str ====== #\n",
    "orig_testing_features = np.genfromtxt(path_data + 'testing_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading testing features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 13)\n",
      "Labels: (615512,)\n",
      "Testing features: (32648, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Training features:', orig_training_features.shape)\n",
    "print('Labels:', labels.shape)\n",
    "print('Testing features:', orig_testing_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking up some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we might need to remove some features read from file. Here, we remove features by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_features = [\n",
    "    'temporal_difference', # 0\n",
    "    'common_authors', # 1\n",
    "    'same_journal', # 2\n",
    "    'cosine_sim', # 3\n",
    "    'overlapping_title', # 4\n",
    "    'average_degrees', # 5\n",
    "    'common_neighbors', # 6\n",
    "    'jaccard_coefficient', # 7\n",
    "    'avg_pagerank', # 8\n",
    "    'average_betweenness', # 9\n",
    "    'in_kcore', # 10\n",
    "    'adamic_adar', # 11\n",
    "    'katz_index' # 12\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 13)\n"
     ]
    }
   ],
   "source": [
    "# remove very useless features : same_journal (useless), common neighbors (strongly correlated with adamic-adar), page rank (strongly correlated with betweeness)\n",
    "to_remove = []\n",
    "training_features = np.delete(orig_training_features, to_remove, 1)\n",
    "testing_features = np.delete(orig_testing_features, to_remove, 1)\n",
    "features = np.delete(orig_features, to_remove)\n",
    "\n",
    "print('Training features:', training_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(filename, pred):\n",
    "    '''\n",
    "    Write prediction result in a submission file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: name of submission file\n",
    "    pred: prediction array\n",
    "    \n",
    "    '''\n",
    "    with open(path_submission + filename, 'w', newline='') as f:\n",
    "        csv_out = csv.writer(f)\n",
    "        csv_out.writerow(['id','category'])\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Scaling features ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32648"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size = testing_features.shape[0]\n",
    "testing_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-A. SVM without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 4.2013 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and predicting with SVM ====== #\n",
    "clf_svm = svm.LinearSVC(dual=False, C=1.0)\n",
    "clf_svm.fit(training_features, labels)\n",
    "pred_svm = list(clf_svm.predict(testing_features))\n",
    "pred_svm = zip(range(len(testing_features)), pred_svm)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_11.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM: 0.9650 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "svm_scores = cross_val_score(clf_svm, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with SVM: %0.4f (+/- %0.4f)\" % (svm_scores.mean(), svm_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-B. SVM with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC + scaling takes 1.8097 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with SVM and scaled features ====== #\n",
    "clf_svm_scale = svm.LinearSVC(dual=False, C=1.0)\n",
    "clf_svm_scale.fit(training_features_scale, labels)\n",
    "pred_svm_scale = list(clf_svm_scale.predict(testing_features_scale))\n",
    "pred_svm_scale = zip(range(testing_size), pred_svm_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_16_scale.csv', pred_svm_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with SVM scaling: 0.9650 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "svm_scale_scores = cross_val_score(clf_svm_scale, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with SVM scaling: %0.4f (+/- %0.4f)\" % (svm_scale_scores.mean(), svm_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Forest takes 7.3797 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Random Forest ====== #\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(training_features, labels)\n",
    "pred_rf = list(clf_rf.predict(testing_features))\n",
    "pred_rf = zip(range(testing_size), pred_rf)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Random Forest takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_rf_11.csv', pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_val_score(clf_rf, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of RandomForest: %0.4f (+/- %0.4f)\" % (rf_scores.mean(), rf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 7.7782 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression ====== #\n",
    "clf_lg = LogisticRegression()\n",
    "clf_lg.fit(training_features, labels)\n",
    "pred_lg = list(clf_lg.predict(testing_features))\n",
    "pred_lg = zip(range(testing_size), pred_lg)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_07.csv', pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.9669 (+/- 0.0008)\n"
     ]
    }
   ],
   "source": [
    "lg_scores = cross_val_score(clf_lg, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of Logistic Regression: %0.4f (+/- %0.4f)\" % (lg_scores.mean(), lg_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression + scaling takes 2.5854 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_lg_scale = LogisticRegression()\n",
    "clf_lg_scale.fit(training_features_scale, labels)\n",
    "pred_lg_scale = list(clf_lg_scale.predict(testing_features_scale))\n",
    "pred_lg_scale = zip(range(testing_size), pred_lg_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_07_scale.csv', pred_lg_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with Logistic Regression + scaling: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "lg_scale_scores = cross_val_score(clf_lg_scale, training_features_scale, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with Logistic Regression + scaling: %0.4f (+/- %0.4f)\" % (lg_scale_scores.mean(), lg_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Neural Network without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks takes 456.2616 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn.fit(training_features, labels)\n",
    "pred_nn = clf_nn.predict(testing_features)\n",
    "pred_nn = zip(range(testing_size), pred_nn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_16.csv', pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Neural Network: 0.9974 (+/- 0.0039)\n"
     ]
    }
   ],
   "source": [
    "nn_scores = cross_val_score(clf_nn, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score of Neural Network: %0.4f (+/- %0.4f)\" % (nn_scores.mean(), nn_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks + scaling takes 50.3232 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn_scale = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn_scale.fit(training_features_scale, labels)\n",
    "pred_nn_scale = clf_nn_scale.predict(testing_features_scale)\n",
    "pred_nn_scale = zip(range(testing_size), pred_nn_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_10_scale.csv', pred_nn_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of Neural Network + scaling: 0.9978 (+/- 0.0022)\n"
     ]
    }
   ],
   "source": [
    "nn_scale_scores = cross_val_score(clf_nn_scale, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score of Neural Network + scaling: %0.4f (+/- %0.4f)\" % (nn_scale_scores.mean(), nn_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Gradient Boosting takes 35.0845 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_gboost = GradientBoostingClassifier(\n",
    "    loss = 'deviance',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_gboost.fit(training_features, labels)\n",
    "pred_gboost = clf_gboost.predict(testing_features)\n",
    "pred_gboost = zip(range(testing_size), pred_gboost)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_gboost_05.csv', pred_gboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with Gradient Boosting: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "gd_scores = cross_val_score(clf_gboost, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with Gradient Boosting: %0.4f (+/- %0.4f)\" % (gd_scores.mean(), gd_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adaboost takes 47.4125 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_ada = GradientBoostingClassifier(\n",
    "    loss = 'exponential',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_ada.fit(training_features, labels)\n",
    "pred_ada = clf_ada.predict(testing_features)\n",
    "pred_ada = zip(range(testing_size), pred_ada)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Adaboost takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_ada_05.csv', pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with AdaBoost: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "ada_scores = cross_val_score(clf_ada, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with AdaBoost: %0.4f (+/- %0.4f)\" % (ada_scores.mean(), ada_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating to pick up the optimal number of neighbors takes 4485.4285 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, labels, test_size=0.35, random_state=42)\n",
    "\n",
    "myList = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "\n",
    "end = time.time()\n",
    "print('Cross-validating to pick up the optimal number of neighbors takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 11\n"
     ]
    }
   ],
   "source": [
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "_neighbors = list(neighbors)\n",
    "optimal_k = _neighbors[np.argmin(MSE)]\n",
    "print('The optimal number of neighbors is %d' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with k-nearest neighbors takes 44.9709 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training & predicting with k-Neareat Neighbors ====== #\n",
    "clf_knn = KNeighborsClassifier(\n",
    "    n_neighbors = optimal_k\n",
    ")\n",
    "clf_knn.fit(training_features, labels)\n",
    "pred_knn = clf_knn.predict(testing_features)\n",
    "pred_knn = zip(range(testing_size), pred_knn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with k-nearest neighbors takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_knn_01.csv', pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with K-NearestNeighbors: 0.9588 (+/- 0.0008)\n"
     ]
    }
   ],
   "source": [
    "knn_scores = cross_val_score(clf_knn, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"F1-score with K-NearestNeighbors: %0.4f (+/- %0.4f)\" % (knn_scores.mean(), knn_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'jaccard_coefficient' of importance 0.27180\n",
      "Feature 'katz_index' of importance 0.26861\n",
      "Feature 'adamic_adar' of importance 0.20545\n",
      "Feature 'cosine_sim' of importance 0.10024\n",
      "Feature 'common_neighbors' of importance 0.05078\n",
      "Feature 'average_degrees' of importance 0.03634\n",
      "Feature 'in_kcore' of importance 0.03274\n",
      "Feature 'avg_pagerank' of importance 0.02964\n",
      "Feature 'average_betweenness' of importance 0.00196\n",
      "Feature 'overlapping_title' of importance 0.00186\n",
      "Feature 'common_authors' of importance 0.00029\n",
      "Feature 'temporal_difference' of importance 0.00028\n",
      "Feature 'same_journal' of importance 0.00003\n"
     ]
    }
   ],
   "source": [
    "# ====== compute feature importance ====== #\n",
    "idx = np.argsort(-clf_rf.feature_importances_) # sort the indicator of feature important by decreasing order\n",
    "\n",
    "for i in idx:\n",
    "    print('Feature \\'%s\\' of importance %.5f' % (features[i], clf_rf.feature_importances_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
