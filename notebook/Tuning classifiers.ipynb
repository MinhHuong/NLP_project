{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model and Issuing predictions (main script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading libraries takes 0.8376 s\n"
     ]
    }
   ],
   "source": [
    "# import time to find consuming steps\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# utility libraries\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "from sklearn import preprocessing as pre\n",
    "\n",
    "# classifier for classification\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "end = time.time()\n",
    "print('Loading libraries takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset (training, testing, node information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../data/' # path to the data\n",
    "path_submission = '../submission/' # path to submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training set & extracting labels takes 3.0708 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training data as str ====== #\n",
    "training = np.genfromtxt(path_data + 'training_set.txt', dtype=str)\n",
    "\n",
    "# ====== extract labels ====== #\n",
    "labels = training[:, 2].astype(int) # get the labels\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training set & extracting labels takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training features takes 8.6342 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read training features ====== #\n",
    "orig_training_features = np.genfromtxt(path_data + 'training_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading training features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing features takes 0.4785 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== read testing features as str ====== #\n",
    "orig_testing_features = np.genfromtxt(path_data + 'testing_features.csv', delimiter=',', skip_header=1, dtype=float)\n",
    "\n",
    "end = time.time()\n",
    "print('Reading testing features takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 13)\n",
      "Labels: (615512,)\n",
      "Testing features: (32648, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Training features:', orig_training_features.shape)\n",
    "print('Labels:', labels.shape)\n",
    "print('Testing features:', orig_testing_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking up some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we might need to remove some features read from file. Here, we remove features by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_features = [\n",
    "    'temporal_difference', # 0\n",
    "    'common_authors', # 1\n",
    "    'same_journal', # 2\n",
    "    'cosine_sim', # 3\n",
    "    'overlapping_title', # 4\n",
    "    'average_degrees', # 5\n",
    "    'common_neighbors', # 6\n",
    "    'jaccard_coefficient', # 7\n",
    "    'avg_pagerank', # 8\n",
    "    'average_betweenness', # 9\n",
    "    'in_kcore', # 10\n",
    "    'adamic_adar', # 11\n",
    "    'katz_index' # 12\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (615512, 10)\n"
     ]
    }
   ],
   "source": [
    "# remove very useless features : same_journal (useless), common neighbors (strongly correlated with adamic-adar), page rank (strongly correlated with betweeness)\n",
    "to_remove = [2, 6, 8]\n",
    "training_features = np.delete(orig_training_features, to_remove, 1)\n",
    "testing_features = np.delete(orig_testing_features, to_remove, 1)\n",
    "features = np.delete(orig_features, to_remove)\n",
    "\n",
    "print('Training features:', training_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(filename, pred):\n",
    "    '''\n",
    "    Write prediction result in a submission file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: name of submission file\n",
    "    pred: prediction array\n",
    "    \n",
    "    '''\n",
    "    with open(path_submission + filename, 'w', newline='') as f:\n",
    "        csv_out = csv.writer(f)\n",
    "        csv_out.writerow(['id','category'])\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Scaling features ====== #\n",
    "training_features_scale = pre.scale(training_features)\n",
    "testing_features_scale = pre.scale(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32648"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size = testing_features.shape[0]\n",
    "testing_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-A. SVM without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC takes 139.0131 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and predicting with SVM ====== #\n",
    "clf_svm = svm.LinearSVC()\n",
    "clf_svm.fit(training_features, labels)\n",
    "pred_svm = list(clf_svm.predict(testing_features))\n",
    "pred_svm = zip(range(len(testing_features)), pred_svm)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_11.csv', pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SVM scaling: 0.9650 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "svm_scores = cross_val_score(clf_svm, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy with SVM scaling: %0.4f (+/- %0.4f)\" % (svm_scale_scores.mean(), svm_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-B. SVM with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SVM Linear SVC + scaling takes 1.0714 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with SVM and scaled features ====== #\n",
    "clf_svm_scale = svm.LinearSVC(C=1.0, dual=False)\n",
    "clf_svm_scale.fit(training_features_scale, labels)\n",
    "pred_svm_scale = list(clf_svm_scale.predict(testing_features_scale))\n",
    "pred_svm_scale = zip(range(testing_size), pred_svm_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_svm_15_scale.csv', pred_svm_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SVM scaling: 0.9632 (+/- 0.0013)\n"
     ]
    }
   ],
   "source": [
    "svm_scale_scores = cross_val_score(clf_svm_scale, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy with SVM scaling: %0.4f (+/- %0.4f)\" % (svm_scale_scores.mean(), svm_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-C. SVM with RBF as kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beware: takes too long to complete\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# # ====== training and prediction with SVM and scaled features ====== #\n",
    "# clf_svm_rbf = svm.SVC(kernel='rbf')\n",
    "# clf_svm_rbf.fit(training_features_scale, labels)\n",
    "# pred_svm_rbf = list(clf_svm_rbf.predict(testing_features_scale))\n",
    "# pred_svm_rbf = zip(range(testing_size), pred_svm_rbf)\n",
    "\n",
    "# end = time.time()\n",
    "# print('Training with SVM Linear SVC + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_submission('submission_svm_rbf_01_scale.csv', pred_svm_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Forest takes 3.1240 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Random Forest ====== #\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(training_features, labels)\n",
    "pred_rf = list(clf_rf.predict(testing_features))\n",
    "pred_rf = zip(range(testing_size), pred_rf)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Random Forest takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_rf_11.csv', pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest: 1.0000 (+/- 0.0000)\n"
     ]
    }
   ],
   "source": [
    "rf_scores = cross_val_score(clf_rf, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of RandomForest: %0.4f (+/- %0.4f)\" % (rf_scores.mean(), rf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Logistic Regression without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression takes 7.7417 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression ====== #\n",
    "clf_lg = LogisticRegression()\n",
    "clf_lg.fit(training_features, labels)\n",
    "pred_lg = list(clf_lg.predict(testing_features))\n",
    "pred_lg = zip(range(testing_size), pred_lg)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_07.csv', pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.9669 (+/- 0.0008)\n"
     ]
    }
   ],
   "source": [
    "lg_scores = cross_val_score(clf_lg, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of Logistic Regression: %0.4f (+/- %0.4f)\" % (lg_scores.mean(), lg_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Logistic Regression with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Logistic Regression + scaling takes 2.8288 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== training and prediction with Logistic Regression + scaling ====== #\n",
    "clf_lg_scale = LogisticRegression()\n",
    "clf_lg_scale.fit(training_features_scale, labels)\n",
    "pred_lg_scale = list(clf_lg_scale.predict(testing_features_scale))\n",
    "pred_lg_scale = zip(range(testing_size), pred_lg_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Logistic Regression + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_lg_07_scale.csv', pred_lg_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Neural Network without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks takes 562.4595 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn.fit(training_features, labels)\n",
    "pred_nn = clf_nn.predict(testing_features)\n",
    "pred_nn = zip(range(testing_size), pred_nn)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_15.csv', pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network + scaling: 0.9912 (+/- 0.0195)\n"
     ]
    }
   ],
   "source": [
    "nn_scores = cross_val_score(clf_nn, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of Neural Network + scaling: %0.4f (+/- %0.4f)\" % (nn_scores.mean(), nn_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Neural Networks + scaling takes 49.4728 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_nn_scale = MLPClassifier(\n",
    "    hidden_layer_sizes = (50,60,70,40,50,30,20,10),\n",
    "    activation = 'relu',\n",
    "    solver = 'adam',\n",
    "    early_stopping = True\n",
    ")\n",
    "clf_nn_scale.fit(training_features_scale, labels)\n",
    "pred_nn_scale = clf_nn_scale.predict(testing_features_scale)\n",
    "pred_nn_scale = zip(range(testing_size), pred_nn_scale)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Neural Networks + scaling takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_nn_10_scale.csv', pred_nn_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_scale_scores = cross_val_score(clf_nn_scale, training_features, labels, cv=5, scoring='f1')\n",
    "print(\"Accuracy of Neural Network + scaling: %0.4f (+/- %0.4f)\" % (nn_scale_scores.mean(), nn_scale_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Gradient Boosting takes 442.9257 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_gboost = GradientBoostingClassifier(\n",
    "    loss = 'deviance',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_gboost.fit(training_features, labels)\n",
    "pred_gboost = clf_gboost.predict(testing_features)\n",
    "pred_gboost = zip(range(testing_size), pred_gboost)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Gradient Boosting takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_gboost_05.csv', pred_gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adaboost takes 300.6069 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# ====== Training and predicting with Gradient Boosting ====== #\n",
    "clf_ada = GradientBoostingClassifier(\n",
    "    loss = 'exponential',\n",
    "    n_estimators = 200\n",
    ")\n",
    "clf_ada.fit(training_features, labels)\n",
    "pred_ada = clf_ada.predict(testing_features)\n",
    "pred_ada = zip(range(testing_size), pred_ada)\n",
    "\n",
    "end = time.time()\n",
    "print('Training with Adaboost takes %.4f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission('submission_ada_05.csv', pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'katz_index' of importance 0.70817\n",
      "Feature 'adamic_adar' of importance 0.16941\n",
      "Feature 'jaccard_coefficient' of importance 0.08326\n",
      "Feature 'in_kcore' of importance 0.03162\n",
      "Feature 'cosine_sim' of importance 0.00695\n",
      "Feature 'average_degrees' of importance 0.00033\n",
      "Feature 'average_betweenness' of importance 0.00014\n",
      "Feature 'common_authors' of importance 0.00009\n",
      "Feature 'temporal_difference' of importance 0.00002\n",
      "Feature 'overlapping_title' of importance 0.00001\n"
     ]
    }
   ],
   "source": [
    "# ====== compute feature importance ====== #\n",
    "idx = np.argsort(-clf_rf.feature_importances_) # sort the indicator of feature important by decreasing order\n",
    "\n",
    "for i in idx:\n",
    "    print('Feature \\'%s\\' of importance %.5f' % (features[i], clf_rf.feature_importances_[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
